{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from aws_s3 import AwsS3\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "class Crawler():\n",
    "    \n",
    "    def get_matches_report_detail() -> str:\n",
    "\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "        driver = webdriver.Remote('http://127.0.0.1:4444/wd/hub', options = options)\n",
    "\n",
    "        path_write = 'raw/trackergg/matches_report_details/'\n",
    "\n",
    "        matches = read_csv(\"matches.csv\")\n",
    "        matches = matches['match_id'].to_list()\n",
    "\n",
    "        for matche in matches:\n",
    "            \n",
    "            driver.get('https://api.tracker.gg/api/v2/valorant/standard/matches/{}'.format(matche))\n",
    "            \n",
    "            data_pre = driver.find_element('xpath', '//pre').text\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            file_format = '.txt'\n",
    "            \n",
    "            AwsS3.upload_file(data_pre, path_write, file_format)\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        # return data_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_S3_BUCKET = os.getenv(\"AWS_S3_BUCKET\")\n",
    "\n",
    "\n",
    "class AwsS3():\n",
    "\n",
    "    \n",
    "    def upload_file(data : object, path : str, file_format) -> bool:\n",
    "\n",
    "        \"\"\"\n",
    "            Upload a file to an S3 bucket\n",
    "            :param file_name: File to upload\n",
    "            :param bucket: Bucket to upload to\n",
    "            :param object_name: S3 object name. If not specified then file_name is used\n",
    "            :return: True if file was uploaded, else False\n",
    "        \"\"\"\n",
    "\n",
    "        date = datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "        file_name = 'valorant_reports{}{}'.format(date, file_format)\n",
    "        input = path + file_name\n",
    "\n",
    "        \n",
    "        s3 = boto3.client(\"s3\", aws_access_key_id = AWS_ACCESS_KEY_ID, aws_secret_access_key = AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "        try:\n",
    "            s3.put_object(Bucket = AWS_S3_BUCKET, Body = data, Key = input)\n",
    "\n",
    "        except ClientError as e:\n",
    "            logging.error(e)\n",
    "\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def get_file(path : str, file_name : str) -> str:\n",
    "\n",
    "        \"\"\"\n",
    "            Get a file to an S3 bucket\n",
    "            :param Path: Path to get\n",
    "            :param bucket: Bucket to upload to\n",
    "            :param object_name: S3 object name. If not specified then file_name is used\n",
    "            :return: True if file was uploaded, else False\n",
    "        \"\"\"\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        try:\n",
    "\n",
    "            response = s3.get_object(Bucket = AWS_S3_BUCKET, Key = file_name)\n",
    "            data = response['Body'].read()\n",
    "            data_str = data.decode('utf-8')\n",
    "\n",
    "        except ClientError as e:\n",
    "            logging.error(e)\n",
    "\n",
    "\n",
    "        return data_str\n",
    "        \n",
    "\n",
    "    def get_files_list(path_read : str) -> list:\n",
    "\n",
    "        s3 = boto3.resource('s3')\n",
    "        bucket = s3.Bucket(AWS_S3_BUCKET)\n",
    "        files_list = bucket.objects.filter(Prefix = path_read)\n",
    "        files_list = list(files_list)\n",
    "        \n",
    "        if len(files_list) > 1: \n",
    "            del files_list[0]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_s3 import AwsS3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "class DataCleaner():\n",
    "    \n",
    "    def data_cleaner_matches():\n",
    "\n",
    "        path_read = 'raw/trackergg/matches_report_details/'\n",
    "        path_write = 'cleaned/trackergg/matches_report_details/'\n",
    "        \n",
    "        df_aux = pd.DataFrame()\n",
    "\n",
    "        files = AwsS3.get_files_list(path_read)\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for file in files:\n",
    "            file = file.key\n",
    "            data_s3 = AwsS3.get_file(path_read, file)\n",
    "            data_json = json.loads(data_s3)\n",
    "            \n",
    "            expiryDate : str = data_json[\"data\"][\"expiryDate\"]\n",
    "            metadata : dict = data_json[\"data\"][\"metadata\"]\n",
    "            segments = data_json['data']['segments']\n",
    "\n",
    "            data = []\n",
    "\n",
    "\n",
    "            for segment in segments:\n",
    "                segment_type: str = segment[\"type\"]\n",
    "                attributes : dict = segment[\"attributes\"]\n",
    "                segment_metadata : dict = segment[\"metadata\"]\n",
    "                expiryDate : str = segment[\"expiryDate\"]\n",
    "                \n",
    "                stat_dict = {}\n",
    "                stats : dict = segment[\"stats\"]\n",
    "                for stat, stat_data in stats.items():\n",
    "                    stat_keys = stat_data.keys()\n",
    "                    stat_columns = [f'{stat}_{col}' for col in stat_keys]\n",
    "                    stat_values = stat_data.values()\n",
    "                    _stat_dict = {k: v for k, v in zip(stat_columns, stat_values)}\n",
    "                    stat_dict.update(_stat_dict)\n",
    "            \n",
    "                row = {}  \n",
    "                row[\"match_id\"] = data_json['data'][\"attributes\"][\"id\"]\n",
    "                row[\"expiryDate\"] = expiryDate\n",
    "                row[\"segment_type\"] = segment_type\n",
    "                row.update(attributes)\n",
    "                row.update(segment_metadata)\n",
    "                row.update(stat_dict)\n",
    "                data.append(row)\n",
    "            \n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "            \n",
    "            return df\n",
    "\n",
    "                # # data.append(row)\n",
    "           \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataCleaner.data_cleaner_matches()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.loads(data.to_json(orient='records')))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('matches_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_summary = df[['segment_type', 'teamId', 'name', 'hasWon',\n",
    "\t                  'roundsWon_rank', 'roundsWon_percentile',\t\n",
    "                      'roundsWon_displayName', 'roundsWon_displayCategory',\n",
    "                      'roundsWon_category', 'roundsWon_value', 'roundsWon_displayValue',\n",
    "                      'roundsWon_displayType', 'roundsLost_rank', 'roundsLost_percentile',\n",
    "                      'roundsLost_displayName', 'roundsLost_displayCategory', 'roundsLost_category',\n",
    "                      'roundsLost_value', 'roundsLost_displayValue', 'roundsLost_displayType',\n",
    "                      'score_rank',\t'score_percentile',\t'score_displayName', 'score_displayCategory', 'score_category',\n",
    "                      'score_value', 'score_displayValue',\t'score_displayType', 'kills_rank', 'kills_percentile',\n",
    "                      'kills_displayName', 'kills_displayCategory', 'kills_category', 'kills_value', 'kills_displayValue',\n",
    "                      'kills_displayType',\t'deaths_rank',\t'deaths_percentile', 'deaths_displayName', 'deaths_displayCategory',\n",
    "                      'deaths_category', 'deaths_value', 'deaths_displayValue',\t'deaths_displayType', 'assists_rank', 'assists_percentile',\n",
    "                      'assists_displayName', 'assists_displayCategory',\t'assists_category',\t'assists_value', 'assists_displayValue',\n",
    "                      'assists_displayType', 'damage_rank',\t'damage_percentile', 'damage_displayName', 'damage_displayCategory', 'damage_category',\n",
    "                      'damage_value', 'damage_displayValue', 'damage_displayType',\n",
    "]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cba5719d159acad27bb7f37d182d27b1d38df28115fbd0d331121e7aca3605"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
